quarto preview
quarto preview
quarto render
quarto render
quarto render
### Shift Leader - Chick-fil-A, Arcadia, CA
![Chick-fil-A Logo](IBM6300/gb_portfolio/chickfila_logo.png)
quarto preview
quarto render
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(dallas_data$price, p = .8, list = FALSE, times = 1)
library(caret)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(dallas_data$price, p = .8, list = FALSE, times = 1)
# Load libraries
library(tidyverse)
library(readr)
library(randomForest)
library(caret)
# Set directory and load dataset
setwd("C:/Users/georg/OneDrive/Documents/IBM6540")
data <- read_delim('apartments_for_rent_classified_100K.csv', delim=';')
# Checking out data
head(data)
str(data)
summary(data)
# Finding city with most data
city_counts <- data %>%
group_by(cityname) %>%
summarise(count = n()) %>%
arrange(desc(count))
most_data_city <- city_counts %>%
slice_max(order_by = count, n = 1) %>%
pull(cityname)
print(most_data_city)
# Filter data for Dallas
dallas_data <- data %>%
filter(cityname == "Dallas") %>%
select(amenities, bedrooms,bathrooms, has_photo,pets_allowed,price,square_feet, latitude, longitude, cityname,time)
#Data Cleaning & Engineering
dallas_data <- dallas_data %>%
drop_na(price, square_feet, bedrooms, bathrooms, amenities) %>%
mutate(amenities = ifelse(amenities == "null", NA, amenities)) %>%
mutate(price_per_sqft = price / square_feet)
# Count number of amenities for each apartment
dallas_data <- dallas_data %>%
mutate(num_amenities = ifelse(is.na(amenities), 0, str_count(amenities, ",") + 1)) %>%
select(-amenities)
# Convert 'has_photo' and 'pets_allowed' to binary numeric variables
dallas_data <- dallas_data %>%
mutate(has_photo = ifelse(tolower(has_photo) %in% c("yes", "thumbnail"), 1, 0),
pets_allowed = ifelse(tolower(pets_allowed) %in% c("cats", "dogs", "cats,dogs"), 1, 0))
head(dallas_data)
# Load libraries
library(tidyverse)
library(readr)
library(randomForest)
head(dallas_data)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(dallas_data$price, p = .8, list = FALSE, times = 1)
trainData <- dallas_data[trainIndex,]
testData <- dallas_data[-trainIndex,]
View(trainData)
View(testData)
View(dallas_data)
# First Model: Linear Regression
model1 <- lm(price ~ square_feet + bedrooms + bathrooms + has_photo + pets_allowed + num_amenities, data = trainData)
summary(model1)
View(model1)
# Predictions and Evaluation for Linear Regression
predictions1 <- predict(model1, newdata = testData)
rmse1 <- sqrt(mean((predictions1 - testData$price)^2))
mae1 <- mean(abs(predictions1 - testData$price))
r2_1 <- summary(model1)$r.squared
# Second Model: Random Forest Regression
model2 <- randomForest(price ~ square_feet + bedrooms + bathrooms + has_photo + pets_allowed + num_amenities, data = trainData)
# Second Model: Random Forest Regression
model2 <- randomForest(price ~ square_feet + bedrooms + bathrooms + has_photo + pets_allowed + num_amenities, data = trainData)
# Predictions and Evaluation for Random Forest
predictions2 <- predict(model2, newdata = testData)
rmse2 <- sqrt(mean((predictions2 - testData$price)^2))
mae2 <- mean(abs(predictions2 - testData$price))
r2_2 <- cor(predictions2, testData$price)^2
# Summary of Model Performance
performance <- data.frame(
Model = c("Linear Regression", "Random Forest"),
RMSE = c(rmse1, rmse2),
MAE = c(mae1, mae2),
R2 = c(r2_1, r2_2)
)
print(performance)
library(tidyverse)
library(tidyverse)
library(tidyverse)
library(readr)
library(randomForest)
library(caret)
library(ggplot2)
data <- read_delim('apartments_for_rent_classified_100K.csv', delim=';')
library(tidyverse)
library(readr)
library(randomForest)
library(caret)
library(ggplot2)
# Predictions and Evaluation for Linear Regression
predictions1 <- predict(model1, newdata = testData)
library(tidyverse)
library(readr)
library(randomForest)
library(caret)
library(ggplot2)
data <- read_delim('apartments_for_rent_classified_100K.csv', delim=';')
# Checking out data
head(data)
str(data)
summary(data)
# Finding city with most data
city_counts <- data %>%
group_by(cityname) %>%
summarise(count = n()) %>%
arrange(desc(count))
most_data_city <- city_counts %>%
slice_max(order_by = count, n = 1) %>%
pull(cityname)
print(most_data_city)
# Filter data for Dallas
dallas_data <- data %>%
filter(cityname == "Dallas") %>%
select(amenities, bedrooms,bathrooms, has_photo,pets_allowed,price,square_feet, latitude, longitude, cityname,time)
#Data Cleaning & Engineering
dallas_data <- dallas_data %>%
drop_na(price, square_feet, bedrooms, bathrooms, amenities) %>%
mutate(amenities = ifelse(amenities == "null", NA, amenities)) %>%
mutate(price_per_sqft = price / square_feet)
# Count number of amenities for each apartment
dallas_data <- dallas_data %>%
mutate(num_amenities = ifelse(is.na(amenities), 0, str_count(amenities, ",") + 1)) %>%
select(-amenities)
# Convert 'has_photo' and 'pets_allowed' to binary numeric variables
dallas_data <- dallas_data %>%
mutate(has_photo = ifelse(tolower(has_photo) %in% c("yes", "thumbnail"), 1, 0),
pets_allowed = ifelse(tolower(pets_allowed) %in% c("cats", "dogs", "cats,dogs"), 1, 0))
head(dallas_data)
# Predictions and Evaluation for Linear Regression
predictions1 <- predict(model1, newdata = testData)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(dallas_data$price, p = .8, list = FALSE, times = 1)
trainData <- dallas_data[trainIndex,]
testData <- dallas_data[-trainIndex,]
# First Model: Linear Regression
model1 <- lm(price ~ square_feet + bedrooms + bathrooms + has_photo + pets_allowed + num_amenities, data = trainData)
summary(model1)
# Predictions and Evaluation for Linear Regression
predictions1 <- predict(model1, newdata = testData)
rmse1 <- sqrt(mean((predictions1 - testData$price)^2))
mae1 <- mean(abs(predictions1 - testData$price))
r2_1 <- summary(model1)$r.squared
# Plot actual vs predicted prices
ggplot(testData, aes(x = price, y = predictions1)) +
geom_point(color = 'blue') +
geom_abline(slope = 1, intercept = 0, color = 'red') +
labs(title = 'Linear Regression: Actual vs Predicted Prices',
x = 'Actual Prices',
y = 'Predicted Prices') +
theme_minimal()
# Fit the Random Forest Regression model
model2 <- randomForest(price ~ square_feet + bedrooms + bathrooms + has_photo + pets_allowed + num_amenities, data = trainData)
# Plot actual vs predicted prices
ggplot(testData, aes(x = price, y = predictions1)) +
geom_point(color = 'blue') +
geom_abline(slope = 1, intercept = 0, color = 'red') +
labs(title = 'Linear Regression: Actual vs Predicted Prices',
x = 'Actual Prices',
y = 'Predicted Prices') +
theme_minimal()
# Scatter plot of price vs. number of amenities
ggplot(dallas_data, aes(x = num_amenities, y = price)) +
geom_point(aes(color = as.factor(bedrooms), size = square_feet)) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Price of Apartments vs. Number of Amenities",
x = "Number of Amenities",
y = "Price",
color = "Number of Bedrooms",
size = "Square Feet") +
theme_minimal()
+
geom_point(aes(color = as.factor(bedrooms), size
+
geom_point(aes(color = as.factor(bedrooms), size
ggplot(dallas_data, aes(x = square_feet, y = price))
ggplot(dallas_data, aes(x = square_feet, y = price)) +
geom_point(aes(color = as.factor(bedrooms), size = num_amenities)) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Price of Apartments vs. Square Footage",
x = "Square Footage",
y = "Price",
color = "Number of Bedrooms",
size = "Number of Amenities") +
theme_minimal()
setwd("C:/Users/georg/OneDrive/Documents/IBM6300/gb_portfolio")
